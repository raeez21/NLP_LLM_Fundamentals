{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "555e8d79-323d-43cd-8578-e9bb303ea961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we quantify the finetune of previous notebook (finetune_2models2styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f96d521-5f64-44b3-8168-6011354153a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raeez/.pyenv/versions/jupyter-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import textwrap\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torchinfo import summary\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c714976-61a7-4263-9d9e-4adbfd9e8025",
   "metadata": {},
   "source": [
    "tokenize and find most freq 100 tokensm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e429a7c-b2e6-4544-9564-e42cf9dd3d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Loading weights: 100%|█| 160/160 [00:00<00:00, 1658.53it/s, Materializing param=\n",
      "\u001b[1mGPTNeoForCausalLM LOAD REPORT\u001b[0m from: EleutherAI/gpt-neo-125m\n",
      "Key                                                   | Status     |  | \n",
      "------------------------------------------------------+------------+--+-\n",
      "transformer.h.{0...11}.attn.attention.masked_bias     | UNEXPECTED |  | \n",
      "transformer.h.{0, 2, 4, 6, 8, 10}.attn.attention.bias | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Loading weights: 100%|█| 160/160 [00:00<00:00, 1549.41it/s, Materializing param=\n",
      "\u001b[1mGPTNeoForCausalLM LOAD REPORT\u001b[0m from: EleutherAI/gpt-neo-125m\n",
      "Key                                                   | Status     |  | \n",
      "------------------------------------------------------+------------+--+-\n",
      "transformer.h.{0...11}.attn.attention.masked_bias     | UNEXPECTED |  | \n",
      "transformer.h.{0, 2, 4, 6, 8, 10}.attn.attention.bias | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Eletuther's tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125m')\n",
    "tokenizer.pad_token_id = tokenizer.encode(' ')[0]\n",
    "\n",
    "# load in 2 GPTneos and push to GPU\n",
    "modelAlice = AutoModelForCausalLM.from_pretrained('EleutherAI/gpt-neo-125m')\n",
    "modelEdgar = AutoModelForCausalLM.from_pretrained('EleutherAI/gpt-neo-125m')\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "modelAlice = modelAlice.to(device)\n",
    "modelEdgar = modelEdgar.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d478f011-7d51-4bd6-b7bf-1d7fcf641bbc",
   "metadata": {},
   "source": [
    "Import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae473713-fe0e-4b83-8678-ebad129c2d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (52954 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# throught the looking glass (aka alice in wonderland)\n",
    "text = requests.get('https://www.gutenberg.org/cache/epub/11/pg11.txt').text\n",
    "aliceTokens = torch.tensor(tokenizer.encode(text), dtype=torch.long)\n",
    "\n",
    "# edgar allan Poe\n",
    "text = requests.get('https://www.gutenberg.org/cache/epub/2148/pg2148.txt').text\n",
    "edgarTokens = torch.tensor(tokenizer.encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe306a15-5286-4887-b220-496147c80670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "210616b9-918e-4210-a257-242164f3a81c",
   "metadata": {},
   "source": [
    "Find the most freq tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93c94c0f-f868-4c3d-8510-cbb18f218659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a filtered token vector init to zeros\n",
    "aliceTokensFilt = np.full(len(aliceTokens),-1,dtype=int)\n",
    "# this filter will have the tokens if the token has >2char, or else -1\n",
    "\n",
    "# copy overt the token only if it has >2 char\n",
    "for t in range(len(aliceTokens)):\n",
    "    if len(tokenizer.decode(aliceTokens[t])) > 2:\n",
    "        aliceTokensFilt[t] = aliceTokens[t]\n",
    "\n",
    "# repeat for edgar\n",
    "\n",
    "edgarTokensFilt = np.full(len(edgarTokens),-1,dtype=int)\n",
    "\n",
    "# copy overt the token only if it has >2 char\n",
    "for t in range(len(edgarTokens)):\n",
    "    if len(tokenizer.decode(edgarTokens[t])) > 2:\n",
    "        edgarTokensFilt[t] = edgarTokens[t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f7736d1-7880-4df1-aefd-79ac9e99b08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52954,)\n",
      "torch.Size([52954])\n"
     ]
    }
   ],
   "source": [
    "print(aliceTokensFilt.shape)\n",
    "print(aliceTokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c597b6-a0bf-4b24-8f4a-08a3688c5b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96190/197306 (48.75168519963914) tokens have <3 chara\n",
      "24017/52954 (45.35445858669789) tokens have <3 chara\n"
     ]
    }
   ],
   "source": [
    "# print('Edgar:')\n",
    "print(f'{(edgarTokensFilt==-1).sum()}/{len(edgarTokensFilt)} ({100*(edgarTokensFilt==-1).sum()/len(edgarTokensFilt)}) tokens have <3 chara')\n",
    "print(f'{(aliceTokensFilt==-1).sum()}/{len(aliceTokensFilt)} ({100*(aliceTokensFilt==-1).sum()/len(aliceTokensFilt)}) tokens have <3 chara')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804d5d3-0585-44a2-bd0f-b123bff8d105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceef5e30-5d71-4579-abba-4b7c951bc43d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token   262 appears 1621 times and is  the\n",
      "Token   284 appears  763 times and is  to\n",
      "Token   290 appears  759 times and is  and\n",
      "Token   286 appears  582 times and is  of\n",
      "Token   340 appears  504 times and is  it\n",
      "Token   673 appears  469 times and is  she\n",
      "Token   531 appears  445 times and is  said\n",
      "Token   287 appears  396 times and is  in\n",
      "Token   345 appears  374 times and is  you\n",
      "Token   373 appears  334 times and is  was\n",
      "Token 14862 appears  331 times and is  Alice\n",
      "Token   326 appears  256 times and is  that\n",
      "Token   355 appears  241 times and is  as\n",
      "Token   607 appears  233 times and is  her\n",
      "Token   351 appears  209 times and is  with\n",
      "Token   379 appears  203 times and is  at\n",
      "Token   319 appears  190 times and is  on\n",
      "Token   477 appears  176 times and is  all\n",
      "Token   550 appears  169 times and is  had\n",
      "Token   307 appears  161 times and is  be\n",
      "Token   329 appears  147 times and is  for\n",
      "Token   407 appears  146 times and is  not\n",
      "Token   428 appears  145 times and is  this\n",
      "Token   393 appears  131 times and is  or\n",
      "Token   845 appears  120 times and is  very\n",
      "Token   523 appears  120 times and is  so\n",
      "Token   484 appears  120 times and is  they\n",
      "Token   392 appears  118 times and is and\n",
      "Token  1310 appears  114 times and is  little\n",
      "Token   503 appears  114 times and is  out\n",
      "Token   318 appears  112 times and is  is\n",
      "Token   475 appears  104 times and is  but\n",
      "Token   339 appears   99 times and is  he\n",
      "Token   510 appears   96 times and is  up\n",
      "Token   866 appears   93 times and is  down\n",
      "Token   465 appears   89 times and is  his\n",
      "Token   546 appears   89 times and is  about\n",
      "Token   464 appears   89 times and is The\n",
      "Token   530 appears   88 times and is  one\n",
      "Token  1169 appears   85 times and is the\n",
      "Token   644 appears   84 times and is  what\n",
      "Token   547 appears   83 times and is  were\n",
      "Token   606 appears   81 times and is  them\n",
      "Token   588 appears   81 times and is  like\n",
      "Token   760 appears   80 times and is  know\n",
      "Token   466 appears   79 times and is  do\n",
      "Token  1816 appears   79 times and is  went\n",
      "Token   423 appears   75 times and is  have\n",
      "Token   757 appears   75 times and is  again\n",
      "Token   416 appears   75 times and is  by\n",
      "Token  1807 appears   73 times and is  thought\n",
      "Token  4935 appears   73 times and is  Project\n",
      "Token   611 appears   72 times and is  if\n",
      "Token 20336 appears   71 times and is  Gutenberg\n",
      "Token   714 appears   71 times and is  could\n",
      "Token  5223 appears   71 times and is  herself\n",
      "Token  7542 appears   70 times and is  Queen\n",
      "Token   645 appears   70 times and is  no\n",
      "Token 44484 appears   70 times and is Alice\n",
      "Token   656 appears   66 times and is  into\n",
      "Token   597 appears   66 times and is  any\n",
      "Token   788 appears   65 times and is  then\n",
      "Token   618 appears   65 times and is  when\n",
      "Token   766 appears   65 times and is  see\n",
      "Token   389 appears   64 times and is  are\n",
      "Token   561 appears   64 times and is  would\n",
      "Token   460 appears   64 times and is  can\n",
      "Token   612 appears   62 times and is  there\n",
      "Token   502 appears   62 times and is  me\n",
      "Token  2677 appears   59 times and is  King\n",
      "Token   640 appears   58 times and is  time\n",
      "Token   534 appears   58 times and is  your\n",
      "Token 44123 appears   57 times and is  Mock\n",
      "Token   572 appears   57 times and is  off\n",
      "Token   663 appears   56 times and is  its\n",
      "Token   750 appears   56 times and is  did\n",
      "Token  1436 appears   56 times and is atter\n",
      "Token   616 appears   53 times and is  my\n",
      "Token   835 appears   53 times and is  way\n",
      "Token 33137 appears   53 times and is  Turtle\n",
      "Token   281 appears   53 times and is  an\n",
      "Token  2407 appears   52 times and is  quite\n",
      "Token   881 appears   52 times and is  much\n",
      "Token   670 appears   51 times and is  work\n",
      "Token 33958 appears   51 times and is  Gry\n",
      "Token   584 appears   50 times and is  other\n",
      "Token   278 appears   50 times and is ing\n",
      "Token  2540 appears   50 times and is  began\n",
      "Token  1639 appears   49 times and is You\n",
      "Token   910 appears   49 times and is  say\n",
      "Token   517 appears   49 times and is  more\n",
      "Token  1276 appears   49 times and is  must\n",
      "Token   508 appears   48 times and is  who\n",
      "Token   836 appears   48 times and is  don\n",
      "Token  3809 appears   47 times and is  voice\n",
      "Token   511 appears   45 times and is  their\n",
      "Token  1182 appears   45 times and is  head\n",
      "Token  1517 appears   45 times and is  thing\n",
      "Token  1392 appears   44 times and is  got\n",
      "Token 25498 appears   44 times and is  Rabbit\n"
     ]
    }
   ],
   "source": [
    "# for ALice\n",
    "uniq, counts = np.unique(aliceTokensFilt, return_counts =True)\n",
    "freqidx = np.argsort(counts)[::-1]\n",
    "top100Alice = uniq[freqidx[1:101]]  # IMP: we take from 1 not 0, because in 0th position we will have -1 in the filter\n",
    "\n",
    "# for Edgar\n",
    "uniq, counts = np.unique(edgarTokensFilt, return_counts =True)\n",
    "freqidx = np.argsort(counts)[::-1]\n",
    "top100Edgar = uniq[freqidx[1:101]]\n",
    "\n",
    "for t in top100Alice:\n",
    "    print(f'Token {t:5} appears {np.sum(aliceTokensFilt==t):4} times and is {tokenizer.decode([t])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47e7bb0-19db-4582-b11e-771cbfe767be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token   262 appears 6895 times and is  the\n",
      "Token   286 appears 4470 times and is  of\n",
      "Token   290 appears 2703 times and is  and\n",
      "Token   284 appears 2154 times and is  to\n",
      "Token   287 appears 1905 times and is  in\n",
      "Token   326 appears 1129 times and is  that\n",
      "Token   373 appears 1063 times and is  was\n",
      "Token   340 appears  892 times and is  it\n",
      "Token   616 appears  890 times and is  my\n",
      "Token   351 appears  829 times and is  with\n",
      "Token   543 appears  787 times and is  which\n",
      "Token   355 appears  759 times and is  as\n",
      "Token   550 appears  741 times and is  had\n",
      "Token   318 appears  682 times and is  is\n",
      "Token   379 appears  671 times and is  at\n",
      "Token   407 appears  603 times and is  not\n",
      "Token   465 appears  529 times and is  his\n",
      "Token   329 appears  523 times and is  for\n",
      "Token   422 appears  517 times and is  from\n",
      "Token   428 appears  505 times and is  this\n",
      "Token   383 appears  493 times and is  The\n",
      "Token   416 appears  485 times and is  by\n",
      "Token  2402 appears  481 times and is  upon\n",
      "Token   502 appears  471 times and is  me\n",
      "Token   423 appears  461 times and is  have\n",
      "Token   307 appears  453 times and is  be\n",
      "Token   393 appears  452 times and is  or\n",
      "Token   339 appears  447 times and is  he\n",
      "Token   475 appears  399 times and is  but\n",
      "Token   477 appears  390 times and is  all\n",
      "Token   547 appears  362 times and is  were\n",
      "Token   663 appears  353 times and is  its\n",
      "Token   587 appears  351 times and is  been\n",
      "Token   281 appears  348 times and is  an\n",
      "Token   523 appears  344 times and is  so\n",
      "Token   645 appears  342 times and is  no\n",
      "Token   517 appears  318 times and is  more\n",
      "Token   356 appears  298 times and is  we\n",
      "Token   530 appears  262 times and is  one\n",
      "Token   656 appears  261 times and is  into\n",
      "Token   683 appears  248 times and is  him\n",
      "Token   612 appears  248 times and is  there\n",
      "Token   621 appears  247 times and is  than\n",
      "Token   389 appears  235 times and is  are\n",
      "Token   632 appears  225 times and is  It\n",
      "Token   319 appears  214 times and is  on\n",
      "Token   345 appears  212 times and is  you\n",
      "Token   845 appears  211 times and is  very\n",
      "Token   714 appears  211 times and is  could\n",
      "Token   617 appears  201 times and is  some\n",
      "Token   783 appears  197 times and is  now\n",
      "Token   511 appears  187 times and is  their\n",
      "Token   607 appears  186 times and is  her\n",
      "Token   531 appears  179 times and is  said\n",
      "Token   561 appears  174 times and is  would\n",
      "Token   644 appears  173 times and is  what\n",
      "Token   597 appears  167 times and is  any\n",
      "Token   554 appears  165 times and is  In\n",
      "Token   843 appears  159 times and is  And\n",
      "Token   481 appears  157 times and is  will\n",
      "Token   749 appears  156 times and is  most\n",
      "Token   546 appears  153 times and is  about\n",
      "Token   777 appears  153 times and is  these\n",
      "Token   392 appears  147 times and is and\n",
      "Token   503 appears  143 times and is  out\n",
      "Token   788 appears  142 times and is  then\n",
      "Token   618 appears  141 times and is  when\n",
      "Token   510 appears  140 times and is  up\n",
      "Token   772 appears  137 times and is  even\n",
      "Token   691 appears  137 times and is  only\n",
      "Token   508 appears  135 times and is  who\n",
      "Token   611 appears  135 times and is  if\n",
      "Token   582 appears  134 times and is  man\n",
      "Token   606 appears  133 times and is  them\n",
      "Token   887 appears  133 times and is  But\n",
      "Token   674 appears  131 times and is  our\n",
      "Token   890 appears  131 times and is  long\n",
      "Token   278 appears  125 times and is ing\n",
      "Token   484 appears  125 times and is  they\n",
      "Token   584 appears  123 times and is  other\n",
      "Token   878 appears  122 times and is  before\n",
      "Token   468 appears  120 times and is  has\n",
      "Token   625 appears  120 times and is  over\n",
      "Token  1169 appears  119 times and is the\n",
      "Token   832 appears  118 times and is  through\n",
      "Token   925 appears  118 times and is  made\n",
      "Token   898 appears  116 times and is  own\n",
      "Token  3589 appears  114 times and is  myself\n",
      "Token   880 appears  112 times and is  well\n",
      "Token   717 appears  112 times and is  first\n",
      "Token  1626 appears  112 times and is  within\n",
      "Token   884 appears  110 times and is  such\n",
      "Token   514 appears  110 times and is  us\n",
      "Token  4129 appears  107 times and is  length\n",
      "Token  4145 appears  106 times and is  thus\n",
      "Token   991 appears  103 times and is  still\n",
      "Token   555 appears  102 times and is  un\n",
      "Token  1865 appears  102 times and is  yet\n",
      "Token   910 appears  101 times and is  say\n",
      "Token   750 appears   98 times and is  did\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for t in top100Edgar:\n",
    "    print(f'Token {t:5} appears {np.sum(edgarTokensFilt==t):4} times and is {tokenizer.decode([t])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da1230a-7b7f-4c53-ae8a-db410b87d4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5ce9887-e50e-4a5a-a077-56fa2aa2931a",
   "metadata": {},
   "source": [
    "Quantify common token usage pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae1a196-9ba9-406e-8dc8-1ccc6d028f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.7, 27.8],\n",
       "       [ 0. ,  0. ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numreps = 10 # num random repetitions\n",
    "numtoks = 100 # output length\n",
    "\n",
    "#init\n",
    "tokenUsageAlice = np.zeros((2,2)) # [pre/post, Alice/Edgar]  This variable corresp to Alice text\n",
    "tokenUsageEdgar = np.zeros((2,2)) # [pre/post, Alice/Edgar] This variable corresp to Edgar text\n",
    "\n",
    "# rand start tokens\n",
    "randstarts = torch.randint(tokenizer.vocab_size, (numreps,1)).to(device)\n",
    "\n",
    "# ALICE: generate and store tokens\n",
    "outAlice  = modelAlice.generate(randstarts,\n",
    "                                min_length = numtoks+1,\n",
    "                                max_length = numtoks +1,\n",
    "                                do_sample = True,\n",
    "                                pad_token_id = tokenizer.pad_token_id).cpu()\n",
    "genTokensAlice = outAlice[:,1:].reshape(-1)\n",
    "\n",
    "# EDAGR: smae as above but compressed\n",
    "outEdgar = modelEdgar.generate(randstarts, min_length=numtoks+1, max_length=numtoks+1, do_sample=True, pad_token_id = tokenizer.pad_token_id).cpu()\n",
    "genTokensEdgar = outEdgar[:,1:].reshape(-1)\n",
    "\n",
    "# calculate the percent\n",
    "tokenUsageAlice[0,0] = np.mean (100*np.isin(genTokensAlice,top100Alice))  # ALice Model, ALice tokens\n",
    "tokenUsageAlice[0,1] = np.mean (100*np.isin(genTokensEdgar,top100Alice)) # Edgar model, Alice tokens\n",
    "\n",
    "\n",
    "tokenUsageEdgar[0,0] = np.mean (100*np.isin(genTokensAlice,top100Edgar))  # ALice Model, Edgar tokens\n",
    "tokenUsageEdgar[0,1] = np.mean (100*np.isin(genTokensEdgar,top100Edgar)) # Edgar model, Edgartokens\n",
    "\n",
    "tokenUsageEdgar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4bd689-38b9-4970-a880-b26ea6602471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6a29047-e193-4ea3-ab44-8b3556138cfc",
   "metadata": {},
   "source": [
    "Fine tune the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec8534b5-9dfb-442d-8ee1-c18726f20281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALICE optmizer\n",
    "optimizerAlice = torch.optim.AdamW(modelAlice.parameters(), lr=5e-5, weight_decay=.01)\n",
    "optimizerEdgar = torch.optim.AdamW(modelEdgar.parameters(), lr=5e-5, weight_decay=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c76f14a8-c672-43e0-9e0c-cb47e17be16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 256\n",
    "batch_size = 16\n",
    "num_samples = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3890c77d-fb6e-4394-bde8-46bde4ea4642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0/100, losses (Alice/eDgar): 2.5445785522460938 / 2.7452266216278076\n",
      "Sample: 25/100, losses (Alice/eDgar): 1.9315093755722046 / 2.618189811706543\n",
      "Sample: 50/100, losses (Alice/eDgar): 1.6255204677581787 / 2.599311351776123\n",
      "Sample: 75/100, losses (Alice/eDgar): 1.413282871246338 / 2.5971686840057373\n"
     ]
    }
   ],
   "source": [
    "tokenProbs = np.zeros((num_samples,3))\n",
    "\n",
    "lossAlice = np.zeros(num_samples)\n",
    "lossEdgar = np.zeros(num_samples)\n",
    "\n",
    "for sampli in range(num_samples):\n",
    "    # init batch losses to accumulate\n",
    "\n",
    "    # ALICE fine tuning\n",
    "    # get a batch of data\n",
    "    ix = torch.randint(len(aliceTokens)-seq_len, size = (batch_size,))\n",
    "    X = aliceTokens[ix[:,None] + torch.arange(seq_len)].to(device)\n",
    "\n",
    "    #fwd pass and get loss\n",
    "    modelAlice.zero_grad()\n",
    "    outputs = modelAlice(X, labels=X)\n",
    "\n",
    "    # backprop and store loss\n",
    "    outputs.loss.backward()\n",
    "    optimizerAlice.step()\n",
    "    lossAlice[sampli] = outputs.loss.item()\n",
    "\n",
    "\n",
    "    #EDGAR fine tuning\n",
    "    ix = torch.randint(len(edgarTokens)-seq_len, size = (batch_size,))\n",
    "    X = edgarTokens[ix[:,None] + torch.arange(seq_len)].to(device)\n",
    "\n",
    "    #fwd pass and get loss\n",
    "    modelEdgar.zero_grad()\n",
    "    outputs = modelEdgar(X, labels=X)\n",
    "\n",
    "    # backprop and store loss\n",
    "    outputs.loss.backward()\n",
    "    optimizerAlice.step()\n",
    "    lossEdgar[sampli] = outputs.loss.item()\n",
    "\n",
    "    if sampli%25==0:\n",
    "        print(f'Sample: {sampli}/{num_samples}, losses (Alice/eDgar): {lossAlice[sampli]} / {lossEdgar[sampli]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85023d5f-1bc5-4156-988e-80605e067135",
   "metadata": {},
   "source": [
    "Evaluating the fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2ec2fea-5986-4e0c-bd84-a3a437d7ecc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.7, 27.8],\n",
       "       [23.7, 30.3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# rand start tokens\n",
    "randstarts = torch.randint(tokenizer.vocab_size, (numreps,1)).to(device)\n",
    "\n",
    "# ALICE: generate and store tokens\n",
    "outAlice  = modelAlice.generate(randstarts,\n",
    "                                min_length = numtoks+1,\n",
    "                                max_length = numtoks +1,\n",
    "                                do_sample = True,\n",
    "                                pad_token_id = tokenizer.pad_token_id).cpu()\n",
    "genTokensAlice = outAlice[:,1:].reshape(-1)\n",
    "\n",
    "# EDAGR: smae as above but compressed\n",
    "outEdgar = modelEdgar.generate(randstarts, min_length=numtoks+1, max_length=numtoks+1, do_sample=True, pad_token_id = tokenizer.pad_token_id).cpu()\n",
    "genTokensEdgar = outEdgar[:,1:].reshape(-1)\n",
    "\n",
    "# calculate the percent\n",
    "tokenUsageAlice[1,0] = np.mean (100*np.isin(genTokensAlice,top100Alice))  # ALice Model, ALice tokens\n",
    "tokenUsageAlice[1,1] = np.mean (100*np.isin(genTokensEdgar,top100Alice)) # Edgar model, Alice tokens\n",
    "\n",
    "\n",
    "tokenUsageEdgar[1,0] = np.mean (100*np.isin(genTokensAlice,top100Edgar))  # ALice Model, Edgar tokens\n",
    "tokenUsageEdgar[1,1] = np.mean (100*np.isin(genTokensEdgar,top100Edgar)) # Edgar model, Edgartokens\n",
    "\n",
    "tokenUsageEdgar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b4aa510-6a74-445d-b617-faec42349c63",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m _,axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m3.5\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m \u001b[43maxs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1.8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtokenUsageAlice\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAlice tokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbar([\u001b[38;5;241m1.2\u001b[39m,\u001b[38;5;241m2.2\u001b[39m],tokenUsageEdgar[\u001b[38;5;241m0\u001b[39m:], width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.4\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEdgar tokens\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m minmaxY \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msort(np\u001b[38;5;241m.\u001b[39mconcatenate((tokenUsageAlice[\u001b[38;5;241m0\u001b[39m,:], tokenUsageEdgar[\u001b[38;5;241m0\u001b[39m,:])))[[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]]\n",
      "File \u001b[0;32m~/.pyenv/versions/jupyter-env/lib/python3.10/site-packages/matplotlib/__init__.py:1521\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1527\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1528\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/.pyenv/versions/jupyter-env/lib/python3.10/site-packages/matplotlib/axes/_axes.py:2646\u001b[0m, in \u001b[0;36mAxes.bar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2643\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(left, bottom, width, height, facecolor, edgecolor, linewidth,\n\u001b[1;32m   2644\u001b[0m            hatch, patch_labels)\n\u001b[1;32m   2645\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l, b, w, h, c, e, lw, htch, lbl \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[0;32m-> 2646\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmpatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRectangle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2649\u001b[0m \u001b[43m        \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlbl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhtch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2654\u001b[0m     r\u001b[38;5;241m.\u001b[39m_internal_update(kwargs)\n\u001b[1;32m   2655\u001b[0m     r\u001b[38;5;241m.\u001b[39mget_path()\u001b[38;5;241m.\u001b[39m_interpolation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/jupyter-env/lib/python3.10/site-packages/matplotlib/patches.py:772\u001b[0m, in \u001b[0;36mRectangle.__init__\u001b[0;34m(self, xy, width, height, angle, rotation_point, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;129m@_docstring\u001b[39m\u001b[38;5;241m.\u001b[39minterpd\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, xy, width, height, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    750\u001b[0m              angle\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, rotation_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    751\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;124;03m        %(Patch:kwdoc)s\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 772\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x0 \u001b[38;5;241m=\u001b[39m xy[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y0 \u001b[38;5;241m=\u001b[39m xy[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/jupyter-env/lib/python3.10/site-packages/matplotlib/patches.py:92\u001b[0m, in \u001b[0;36mPatch.__init__\u001b[0;34m(self, edgecolor, facecolor, color, linewidth, linestyle, antialiased, hatch, fill, capstyle, joinstyle, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dash_pattern \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# offset, dash (scaled by linewidth)\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_linestyle(linestyle)\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_linewidth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_antialiased(antialiased)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_hatch(hatch)\n",
      "File \u001b[0;32m~/.pyenv/versions/jupyter-env/lib/python3.10/site-packages/matplotlib/patches.py:439\u001b[0m, in \u001b[0;36mPatch.set_linewidth\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     w \u001b[38;5;241m=\u001b[39m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatch.linewidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linewidth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dash_pattern \u001b[38;5;241m=\u001b[39m mlines\u001b[38;5;241m.\u001b[39m_scale_dashes(\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unscaled_dash_pattern, w)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0UAAAE+CAYAAABC/bueAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAG9BJREFUeJzt3X2MFdX5B/AHFgFNBbUUELqWqvWtCigIRST+bKibaLD80ZSqAUp8qdUaC2kFRMF3LL6UtK4SUat/1II1YowQrFKJsdIQQRJtBaOoUCMLxPJS1EVhfplplrJwV7mL7C73fD7JCDM7597h5O48fueeOdMuy7IsAAAAEtW+tQ8AAACgNQlFAABA0oQiAAAgaUIRAACQNKEIAABImlAEAAAkTSgCAACSJhQBAABJE4oAAICkCUUAAEDSyg5FL730UowYMSJ69eoV7dq1i6effvpL2yxevDjOOOOM6NSpUxx//PHx6KOPNvd4AaARdQmAFg9F27Zti379+kVtbe0+7f/uu+/GBRdcEOeee26sWLEifvnLX8Zll10Wzz33XHOOFwAaUZcA2F/tsizLmt24XbuYN29ejBw5ssl9Jk6cGPPnz4833nhj17af/OQnsWnTpli4cGFz3xoA9qIuAdAcHeIAW7JkSQwfPrzRtpqamuLKXFPq6+uLpcHOnTvjo48+iq9//etFwQOgZeTXzbZu3VoMTWvfvjJuQ1WXAA5u2QGoTQc8FK1bty569OjRaFu+vmXLlvjkk0/i0EMP3avN9OnT4+abbz7QhwbAPlq7dm1885vfjEqgLgFUhrVfYW064KGoOSZPnhwTJkzYtb558+Y45phjin94ly5dWvXYAFKSB4Xq6uo4/PDDI2XqEkBl16YDHop69uwZdXV1jbbl63kRKXU1LpfPBpQve8rbKD4ALa+ShoipSwCVod1XWJsO+ADxIUOGxKJFixpte/7554vtANDS1CUA9jsU/ec//ymmMM2XhqlN87+vWbNm1xCDMWPG7Nr/yiuvjNWrV8d1110XK1eujPvvvz+eeOKJGD9+fLlvDQB7UZcAaPFQ9Oqrr8bpp59eLLl8jHX+96lTpxbrH3744a5ClPv2t79dTH2aX4XLnyNxzz33xEMPPVTM9AMA+0tdAqBVn1PUkjdTde3atbix1dhtgJbj/FuafgGorHNwZTx0AgAAoJmEIgAAIGlCEQAAkDShCAAASJpQBAAAJE0oAgAAkiYUAQAASROKAACApAlFAABA0oQiAAAgaUIRAACQNKEIAABImlAEAAAkTSgCAACSJhQBAABJE4oAAICkCUUAAEDShCIAACBpQhEAAJA0oQgAAEiaUAQAACRNKAIAAJImFAEAAEkTigAAgKQJRQAAQNKEIgAAIGlCEQAAkDShCAAASJpQBAAAJE0oAgAAkiYUAQAASROKAACApAlFAABA0oQiAAAgaUIRAACQNKEIAABImlAEAAAkTSgCAACSJhQBAABJE4oAAICkCUUAAEDShCIAACBpQhEAAJC0ZoWi2tra6NOnT3Tu3DkGDx4cS5cu/cL9Z86cGSeeeGIceuihUV1dHePHj49PP/20uccMAHtRmwBosVA0d+7cmDBhQkybNi2WL18e/fr1i5qamli/fn3J/R9//PGYNGlSsf+bb74ZDz/8cPEa119/fbMPGgB2pzYB0KKh6N57743LL788xo0bF6ecckrMmjUrDjvssHjkkUdK7v/KK6/E0KFD4+KLLy6u4J133nlx0UUXfekVPADYV2oTAC0WirZv3x7Lli2L4cOH/+8F2rcv1pcsWVKyzVlnnVW0aSg0q1evjgULFsT555/f5PvU19fHli1bGi0A0Fq1SV0CqGwdytl548aNsWPHjujRo0ej7fn6ypUrS7bJr8Ll7c4+++zIsiw+//zzuPLKK79wiML06dPj5ptvLufQAEhUS9QmdQmgsh3w2ecWL14cd9xxR9x///3FOO+nnnoq5s+fH7feemuTbSZPnhybN2/etaxdu/ZAHyYACSm3NqlLAJWtrG+KunXrFlVVVVFXV9doe77es2fPkm1uvPHGGD16dFx22WXF+mmnnRbbtm2LK664IqZMmVIMcdhTp06digUA2kJtUpcAKltZ3xR17NgxBgwYEIsWLdq1befOncX6kCFDSrb5+OOP9youefHK5UMWAGB/qE0AtOg3Rbl8ytOxY8fGwIEDY9CgQcVzHvKra/mMP7kxY8ZE7969i/HXuREjRhSzAp1++unFcyPefvvt4gpdvr2hAAHA/lCbAGjRUDRq1KjYsGFDTJ06NdatWxf9+/ePhQsX7rrBdc2aNY2uvt1www3Rrl274s8PPvggvvGNbxRF5/bbb9+vAweABmoTAPujXXYQjBPIpz7t2rVrcXNrly5dWvtwAJLh/FuafgGorHPwAZ99DgAAoC0TigAAgKQJRQAAQNKEIgAAIGlCEQAAkDShCAAASJpQBAAAJE0oAgAAkiYUAQAASROKAACApAlFAABA0oQiAAAgaUIRAACQNKEIAABImlAEAAAkTSgCAACSJhQBAABJE4oAAICkCUUAAEDShCIAACBpQhEAAJA0oQgAAEiaUAQAACRNKAIAAJImFAEAAEkTigAAgKQJRQAAQNKEIgAAIGlCEQAAkDShCAAASJpQBAAAJE0oAgAAkiYUAQAASROKAACApAlFAABA0oQiAAAgaUIRAACQNKEIAABImlAEAAAkTSgCAACSJhQBAABJE4oAAICkCUUAAEDSmhWKamtro0+fPtG5c+cYPHhwLF269Av337RpU1x99dVx9NFHR6dOneKEE06IBQsWNPeYAWAvahMAzdWh3AZz586NCRMmxKxZs4qiM3PmzKipqYlVq1ZF9+7d99p/+/bt8YMf/KD42ZNPPhm9e/eO999/P4444ohmHzQA7E5tAmB/tMuyLCunQV5szjzzzLjvvvuK9Z07d0Z1dXVcc801MWnSpL32zwvUXXfdFStXroxDDjmkWQe5ZcuW6Nq1a2zevDm6dOnSrNcAoHLPvy1dmw6WfgGoRFsOwDm4rOFz+ZW1ZcuWxfDhw//3Au3bF+tLliwp2eaZZ56JIUOGFEMUevToEaeeemrccccdsWPHjibfp76+vvjH7r4AQGvVJnUJoLKVFYo2btxYFIy8gOwuX1+3bl3JNqtXry6GJuTt8rHaN954Y9xzzz1x2223Nfk+06dPL9Jfw5Jf7QOA1qpN6hJAZTvgs8/lQxjyMdsPPvhgDBgwIEaNGhVTpkwphi40ZfLkycXXYQ3L2rVrD/RhApCQcmuTugRQ2cqaaKFbt25RVVUVdXV1jbbn6z179izZJp/VJx+vnbdrcPLJJxdX7/IhDx07dtyrTT4LUL4AQFuoTeoSQGUr65uivEjkV9QWLVrU6Gpbvp6PzS5l6NCh8fbbbxf7NXjrrbeKglQqEAFAOdQmAFp8+Fw+5ens2bPjscceizfffDN+/vOfx7Zt22LcuHHFz8eMGVMMM2iQ//yjjz6Ka6+9tig48+fPL25mzW9uBYCvgtoEQIs+pygfd71hw4aYOnVqMcygf//+sXDhwl03uK5Zs6aY9adBfjPqc889F+PHj4++ffsWz4LIi9DEiRP368ABoIHaBECLPqeoNXgeBEDrcP4tTb8AJPycIgAAgEojFAEAAEkTigAAgKQJRQAAQNKEIgAAIGlCEQAAkDShCAAASJpQBAAAJE0oAgAAkiYUAQAASROKAACApAlFAABA0oQiAAAgaUIRAACQNKEIAABImlAEAAAkTSgCAACSJhQBAABJE4oAAICkCUUAAEDShCIAACBpQhEAAJA0oQgAAEiaUAQAACRNKAIAAJImFAEAAEkTigAAgKQJRQAAQNKEIgAAIGlCEQAAkDShCAAASJpQBAAAJE0oAgAAkiYUAQAASROKAACApAlFAABA0oQiAAAgaUIRAACQNKEIAABImlAEAAAkTSgCAACSJhQBAABJE4oAAICkNSsU1dbWRp8+faJz584xePDgWLp06T61mzNnTrRr1y5GjhzZnLcFgCapTQC0WCiaO3duTJgwIaZNmxbLly+Pfv36RU1NTaxfv/4L27333nvxq1/9KoYNG9bsgwWAUtQmAFo0FN17771x+eWXx7hx4+KUU06JWbNmxWGHHRaPPPJIk2127NgRl1xySdx8881x7LHHful71NfXx5YtWxotANBatUldAqhsZYWi7du3x7Jly2L48OH/e4H27Yv1JUuWNNnulltuie7du8ell166T+8zffr06Nq1666lurq6nMMEICEtUZvUJYDKVlYo2rhxY3FlrUePHo225+vr1q0r2ebll1+Ohx9+OGbPnr3P7zN58uTYvHnzrmXt2rXlHCYACWmJ2qQuAVS2Dgfyxbdu3RqjR48uik63bt32uV2nTp2KBQDaQm1SlwAqW1mhKC8eVVVVUVdX12h7vt6zZ8+99n/nnXeKm1hHjBixa9vOnTv/+8YdOsSqVaviuOOOa/7RA5A8tQmAFh0+17FjxxgwYEAsWrSoUSHJ14cMGbLX/ieddFK8/vrrsWLFil3LhRdeGOeee27xd2OyAdhfahMALT58Lp/ydOzYsTFw4MAYNGhQzJw5M7Zt21bM+JMbM2ZM9O7du7gpNX9WxKmnntqo/RFHHFH8ued2AGgutQmAFg1Fo0aNig0bNsTUqVOLG1j79+8fCxcu3HWD65o1a4pZfwCgpahNAOyPdlmWZdHG5c+DyKdAzWf86dKlS2sfDkAynH9L0y8AlXUOdtkMAABImlAEAAAkTSgCAACSJhQBAABJE4oAAICkCUUAAEDShCIAACBpQhEAAJA0oQgAAEiaUAQAACRNKAIAAJImFAEAAEkTigAAgKQJRQAAQNKEIgAAIGlCEQAAkDShCAAASJpQBAAAJE0oAgAAkiYUAQAASROKAACApAlFAABA0oQiAAAgaUIRAACQNKEIAABImlAEAAAkTSgCAACSJhQBAABJE4oAAICkCUUAAEDShCIAACBpQhEAAJA0oQgAAEiaUAQAACRNKAIAAJImFAEAAEkTigAAgKQJRQAAQNKEIgAAIGlCEQAAkDShCAAASJpQBAAAJE0oAgAAktasUFRbWxt9+vSJzp07x+DBg2Pp0qVN7jt79uwYNmxYHHnkkcUyfPjwL9wfAJpDbQKgxULR3LlzY8KECTFt2rRYvnx59OvXL2pqamL9+vUl91+8eHFcdNFF8eKLL8aSJUuiuro6zjvvvPjggw+afdAAsDu1CYD90S7LsqycBvnVtzPPPDPuu+++Yn3nzp1FMbnmmmti0qRJX9p+x44dxVW5vP2YMWNK7lNfX18sDbZs2VK8x+bNm6NLly7lHC4A+yE//3bt2rXNn38PdG1SlwAquzaV9U3R9u3bY9myZcUwg10v0L59sZ5fadsXH3/8cXz22Wdx1FFHNbnP9OnTi39ow5IXHgBordqkLgFUtrJC0caNG4uraT169Gi0PV9ft27dPr3GxIkTo1evXo2K154mT55cJL+GZe3ateUcJgAJaYnapC4BVLYOLflmd955Z8yZM6cYy53fCNuUTp06FQsAtIXapC4BVLayQlG3bt2iqqoq6urqGm3P13v27PmFbe++++6i8LzwwgvRt2/f5h0tAOxBbQKgRYfPdezYMQYMGBCLFi3atS2/mTVfHzJkSJPtZsyYEbfeemssXLgwBg4cuH9HDAC7UZsAaPHhc/mUp2PHji0KyKBBg2LmzJmxbdu2GDduXPHzfNae3r17Fzel5n7zm9/E1KlT4/HHHy+eH9EwvvtrX/tasQDA/lKbAGjRUDRq1KjYsGFDUUzyItK/f//iKlvDDa5r1qwpZv1p8MADDxQzA/3oRz9q9Dr5syRuuumm/Tp4AMipTQC06HOKWsPB8pwMgErj/FuafgFI+DlFAAAAlUYoAgAAkiYUAQAASROKAACApAlFAABA0oQiAAAgaUIRAACQNKEIAABImlAEAAAkTSgCAACSJhQBAABJE4oAAICkCUUAAEDShCIAACBpQhEAAJA0oQgAAEiaUAQAACRNKAIAAJImFAEAAEkTigAAgKQJRQAAQNKEIgAAIGlCEQAAkDShCAAASJpQBAAAJE0oAgAAkiYUAQAASROKAACApAlFAABA0oQiAAAgaUIRAACQNKEIAABImlAEAAAkTSgCAACSJhQBAABJE4oAAICkCUUAAEDShCIAACBpQhEAAJA0oQgAAEiaUAQAACRNKAIAAJImFAEAAElrViiqra2NPn36ROfOnWPw4MGxdOnSL9z/z3/+c5x00knF/qeddlosWLCguccLACWpTQC0WCiaO3duTJgwIaZNmxbLly+Pfv36RU1NTaxfv77k/q+88kpcdNFFcemll8Zrr70WI0eOLJY33nij2QcNALtTmwDYH+2yLMvKaZBffTvzzDPjvvvuK9Z37twZ1dXVcc0118SkSZP22n/UqFGxbdu2ePbZZ3dt+973vhf9+/ePWbNmlXyP+vr6YmmwefPmOOaYY2Lt2rXRpUuXcg4XgP2wZcuW4hy/adOm6Nq1a7RVB7o2qUsAFV6bsjLU19dnVVVV2bx58xptHzNmTHbhhReWbFNdXZ399re/bbRt6tSpWd++fZt8n2nTpuVBzWKxWCxtZHnnnXeytqolapO6ZLFYLFHRtalDOQFq48aNsWPHjujRo0ej7fn6ypUrS7ZZt25dyf3z7U2ZPHlyMQyiQZ4Cv/Wtb8WaNWva9JXK1krJrlTuTd+Upl+apm9Ka/hG5Kijjoq2qiVqk7q07/wulaZfmqZvStMvLVubygpFLaVTp07Fsqe88PhQ7C3vE/1Smr4pTb80Td+U1r592pOVqkvl87tUmn5pmr4pTb+0TG0q65W6desWVVVVUVdX12h7vt6zZ8+SbfLt5ewPAOVQmwBo0VDUsWPHGDBgQCxatGjXtvxm1nx9yJAhJdvk23ffP/f88883uT8AlENtAqDFh8/lY6rHjh0bAwcOjEGDBsXMmTOLGXzGjRtX/HzMmDHRu3fvmD59erF+7bXXxjnnnBP33HNPXHDBBTFnzpx49dVX48EHH9zn98yHLOTTrJYaupAy/dI0fVOafmmavjm4+6Wla9PB0i+tQd+Upl+apm9K0y8t2zdlT8mdy6c8veuuu4obUvPpS3/3u98V06Hm/u///q94eN6jjz7a6AF5N9xwQ7z33nvxne98J2bMmBHnn3/+V/aPAAC1CYAWDUUAAACVIu3phAAAgOQJRQAAQNKEIgAAIGlCEQAAkLQ2E4pqa2uLmYE6d+5czBa0dOnSL9w/nzXopJNOKvY/7bTTYsGCBVGJyumX2bNnx7Bhw+LII48sluHDh39pPx7Myv3MNMin3m3Xrl2MHDkyKlG5/bJp06a4+uqr4+ijjy6mtjzhhBMq8vep3H7Jp3Q+8cQT49BDD43q6uoYP358fPrpp1FpXnrppRgxYkT06tWr+L14+umnv7TN4sWL44wzzig+L8cff3yjGd0qibrUNLWpNHWpaWpTaWpTG6pLWRswZ86crGPHjtkjjzyS/eMf/8guv/zy7Igjjsjq6upK7v+3v/0tq6qqymbMmJH985//zG644YbskEMOyV5//fWskpTbLxdffHFWW1ubvfbaa9mbb76Z/fSnP826du2a/etf/8oqTbl90+Ddd9/NevfunQ0bNiz74Q9/mKXeL/X19dnAgQOz888/P3v55ZeL/lm8eHG2YsWKLOV++eMf/5h16tSp+DPvk+eeey47+uijs/Hjx2eVZsGCBdmUKVOyp556Kp+JNJs3b94X7r969erssMMOyyZMmFCcf3//+98X5+OFCxdmlURdapraVJq61DS1qTS1qW3VpTYRigYNGpRdffXVu9Z37NiR9erVK5s+fXrJ/X/84x9nF1xwQaNtgwcPzn72s59llaTcftnT559/nh1++OHZY489llWa5vRN3h9nnXVW9tBDD2Vjx46tyOJTbr888MAD2bHHHptt3749q2Tl9ku+7/e///1G2/KT7dChQ7NKti/F57rrrsu++93vNto2atSorKamJqsk6lLT1KbS1KWmqU2lqU1tqy61+vC57du3x7Jly4qv0xu0b9++WF+yZEnJNvn23ffP1dTUNLn/wag5/bKnjz/+OD777LM46qijopI0t29uueWW6N69e1x66aVRiZrTL88880wMGTKkGKLQo0ePOPXUU+OOO+6IHTt2RMr9ctZZZxVtGoYxrF69uhi24cGezr8p16Wc2lSautQ0tak0temr81WdfztEK9u4cWPxIc8/9LvL11euXFmyTf608lL759srRXP6ZU8TJ04sxmPu+UFJsW9efvnlePjhh2PFihVRqZrTL/kJ9a9//WtccsklxYn17bffjquuuqr4H5Zp06ZFqv1y8cUXF+3OPvvs/Nv0+Pzzz+PKK6+M66+/PlLX1Pl3y5Yt8cknnxTj3A926lLT1KbS1KWmqU2lqU1try61+jdFHBh33nlncePmvHnzipv3UrZ169YYPXp0cbNvt27dWvtw2pSdO3cWVykffPDBGDBgQIwaNSqmTJkSs2bNipTlN2zmVyXvv//+WL58eTz11FMxf/78uPXWW1v70OCgpjb9l7r0xdSm0tSmA6vVvynKTwZVVVVRV1fXaHu+3rNnz5Jt8u3l7H8wak6/NLj77ruLwvPCCy9E3759o9KU2zfvvPNOvPfee8VMJrufcHMdOnSIVatWxXHHHRcpfmbyWX0OOeSQol2Dk08+ubjqkn+137Fjx0ixX2688cbif1guu+yyYj2fSWzbtm1xxRVXFIU5H+KQqqbOv126dKmIb4ly6lLT1KbS1KWmqU2lqU1try61eu/lH+z8KsCiRYsanRjy9Xw8aSn59t33zz3//PNN7n8wak6/5GbMmFFcMVi4cGEMHDgwKlG5fZNPkfv6668XQxQalgsvvDDOPffc4u/5lJaVoDmfmaFDhxbDEhqKce6tt94qClIlFJ3m9kt+z8OexaWhOP/3vs90Of+mW5dyalNp6lLT1KbS1Kavzld2/s3ayJSE+RSDjz76aDGV3hVXXFFMSbhu3bri56NHj84mTZrUaOrTDh06ZHfffXcxvee0adMqcurTcvvlzjvvLKZ2fPLJJ7MPP/xw17J169as0pTbN3uq1Fl+yu2XNWvWFLNA/eIXv8hWrVqVPfvss1n37t2z2267LUu5X/JzSt4vf/rTn4qpPv/yl79kxx13XDHDWKXJzw/5VMn5kpeEe++9t/j7+++/X/w875e8f/ac+vTXv/51cf7Np1qu1Cm51aXS1KbS1KWmqU2lqU1tqy61iVCUy+cUP+aYY4oTZz5F4d///vddPzvnnHOKk8XunnjiieyEE04o9s+n4Zs/f35Wicrpl29961vFh2fPJf8lqkTlfmZSKT7l9ssrr7xSTB2cn5jzKVBvv/32YprYlPvls88+y2666aai2HTu3Dmrrq7Orrrqquzf//53VmlefPHFkueNhv7I/8z7Z882/fv3L/oy/8z84Q9/yCqRutQ0tak0dalpalNpalPbqUvt8v98hd9gAQAAHFRa/Z4iAACA1iQUAQAASROKAACApAlFAABA0oQiAAAgaUIRAACQNKEIAABImlAEAAAkTSgCAACSJhQBAABJE4oAAIBI2f8DHmoOvYgZhQUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x350 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_,axs = plt.subplots(1,2,figsize=(10,3.5))\n",
    "\n",
    "axs[0].bar([.8,1.8],tokenUsageAlice[0:], width=.4, label='Alice tokens')\n",
    "axs[0].bar([1.2,2.2],tokenUsageEdgar[0:], width=.4, label='Edgar tokens')\n",
    "minmaxY = np.sort(np.concatenate((tokenUsageAlice[0,:], tokenUsageEdgar[0,:])))[[0,-2]]\n",
    "axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1f6dea4-5cba-4d59-b973-cac5fb28ab75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: unknown file attribute: i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "![title](\"../images/Edgar_Alice_bar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "086a8bb5-25f2-4524-b2aa-5d77c41c5977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/Storage/Learning & Development/NLP_LLM_Fundamentals/finetune'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa1979c4-f63e-41bd-bf14-58e76f22b83a",
   "metadata": {},
   "source": [
    "Qualitative Assesment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54a715da-008e-409a-9725-d8358044544e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Alice model says:\n",
      "What did the Red Queen say to Alice?” she asked.\n",
      "\n",
      "The Gryphon immediately drew its right elbow impatiently, as if\n",
      "watching her. “What is it, then?” it began.\n",
      "\n",
      "“Oh, nothing—you’ve got to speak English,” said the Gryphon hurriedly,\n",
      "without waiting for an answer: for, as the Mock Turtle began to hum\n",
      "violently after her, one by one all the time in a large circle, the\n",
      "Gryphon turned and went on so far up\n",
      "** Edgar model says:\n",
      "What did the Red Queen say to Alice who was in love with her on Alice Day?\n",
      "\n",
      "Alice was the first to get the idea and had to give Alice a heartwarming hug, then she had to give away one heart.\n",
      "\n",
      "Alice’s heart had to go down a new path to become one with her heart, that she would not miss and that her heart would fly to her feet. She was her heart that Alice would never forget. She was in love with Alice on that day.\n",
      "\n",
      "She would lose her heart to this thing called Alice and then she would lose her heart to this man in love with\n"
     ]
    }
   ],
   "source": [
    "x = tokenizer.encode('What did the Red Queen say to Alice', return_tensors='pt').to(device)\n",
    "\n",
    "outAlice = modelAlice.generate(x,max_new_tokens=120, do_sample=True,pad_token_id=50257)\n",
    "outEdgar = modelEdgar.generate(x,max_new_tokens=120, do_sample=True,pad_token_id=50257)\n",
    "\n",
    "print('** Alice model says:')\n",
    "print(tokenizer.decode(outAlice[0].cpu()))\n",
    "\n",
    "\n",
    "print('** Edgar model says:')\n",
    "print(tokenizer.decode(outEdgar[0].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30002e3-59b2-48a3-9c49-2c8e5ff211b1",
   "metadata": {},
   "outputs": [],
   "source": [
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter-env)",
   "language": "python",
   "name": "jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
