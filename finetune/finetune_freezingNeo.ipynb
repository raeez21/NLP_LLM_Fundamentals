{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0171e69d-7cd5-45bf-9078-9527e85530d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we have 2 neo models...one we freeze and one we dont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3613285-3da1-4b03-8c8d-3edaf047b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import textwrap\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torchinfo import summary\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c09d8cd-7dec-443f-95ae-f63956b373fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Loading weights: 100%|█| 160/160 [00:00<00:00, 1238.05it/s, Materializing param=\n",
      "\u001b[1mGPTNeoForCausalLM LOAD REPORT\u001b[0m from: EleutherAI/gpt-neo-125m\n",
      "Key                                                   | Status     |  | \n",
      "------------------------------------------------------+------------+--+-\n",
      "transformer.h.{0...11}.attn.attention.masked_bias     | UNEXPECTED |  | \n",
      "transformer.h.{0, 2, 4, 6, 8, 10}.attn.attention.bias | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Loading weights: 100%|█| 160/160 [00:00<00:00, 1560.12it/s, Materializing param=\n",
      "\u001b[1mGPTNeoForCausalLM LOAD REPORT\u001b[0m from: EleutherAI/gpt-neo-125m\n",
      "Key                                                   | Status     |  | \n",
      "------------------------------------------------------+------------+--+-\n",
      "transformer.h.{0...11}.attn.attention.masked_bias     | UNEXPECTED |  | \n",
      "transformer.h.{0, 2, 4, 6, 8, 10}.attn.attention.bias | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Eletuther's tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125m')\n",
    "tokenizer.pad_token_id = tokenizer.encode(' ')[0]\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "modelFreeze = AutoModelForCausalLM.from_pretrained('EleutherAI/gpt-neo-125m').to(device)\n",
    "modelTrain = AutoModelForCausalLM.from_pretrained('EleutherAI/gpt-neo-125m').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c666d152-0859-45b9-b360-b8164aa541bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77055d98-c735-42b4-afd9-2653552ed944",
   "metadata": {},
   "source": [
    "Import moby dick book and find the most 100 common tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e3510f2-50a4-439d-ad51-1c16338783d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (354293 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moby dick has 354293 tokens, of which 17,259 are unique\n"
     ]
    }
   ],
   "source": [
    "text = requests.get('https://www.gutenberg.org/cache/epub/2701/pg2701.txt').text\n",
    "tokens = tokenizer.encode(text, return_tensors='pt')[0]\n",
    "print(f'Moby dick has {len(tokens)} tokens, of which {len(torch.unique(tokens)):,} are unique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aade0f20-5f8d-4d5b-906b-757e80c90b0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"oken   201 appears 22310 times and is \"\n",
      "Token   198 appears 22310 times and is \"\n",
      "\"\n",
      "Token    11 appears 19216 times and is \",\"\n",
      "Token   262 appears 13157 times and is \" the\"\n",
      "Token    13 appears 7901 times and is \".\"\n",
      "Token   286 appears 6402 times and is \" of\"\n",
      "Token   290 appears 5707 times and is \" and\"\n",
      "Token   447 appears 5359 times and is \"�\"\n",
      "Token   257 appears 4533 times and is \" a\"\n",
      "Token   284 appears 4437 times and is \" to\"\n",
      "Token    26 appears 4167 times and is \";\"\n",
      "Token   287 appears 3853 times and is \" in\"\n",
      "Token   247 appears 2796 times and is \"�\"\n",
      "Token   326 appears 2749 times and is \" that\"\n",
      "Token    12 appears 2584 times and is \"-\"\n",
      "Token    82 appears 2393 times and is \"s\"\n",
      "Token   465 appears 2351 times and is \" his\"\n",
      "Token   340 appears 2108 times and is \" it\"\n",
      "Token   314 appears 1869 times and is \" I\"\n",
      "Token     0 appears 1763 times and is \"!\"\n",
      "Token   318 appears 1657 times and is \" is\"\n",
      "Token   250 appears 1628 times and is \"�\"\n",
      "Token   351 appears 1600 times and is \" with\"\n",
      "Token   339 appears 1596 times and is \" he\"\n",
      "Token   373 appears 1552 times and is \" was\"\n",
      "Token   355 appears 1541 times and is \" as\"\n",
      "Token   251 appears 1487 times and is \"�\"\n",
      "Token   960 appears 1483 times and is \"—\"\n",
      "Token   477 appears 1391 times and is \" all\"\n",
      "Token   329 appears 1359 times and is \" for\"\n",
      "Token   428 appears 1218 times and is \" this\"\n",
      "Token   379 appears 1208 times and is \" at\"\n",
      "Token   416 appears 1110 times and is \" by\"\n",
      "Token   307 appears 1088 times and is \" be\"\n",
      "Token   407 appears 1053 times and is \" not\"\n",
      "Token   475 appears 1024 times and is \" but\"\n",
      "Token    30 appears 1007 times and is \"?\"\n",
      "Token   683 appears 1000 times and is \" him\"\n",
      "Token   422 appears 997 times and is \" from\"\n",
      "Token   319 appears 977 times and is \" on\"\n",
      "Token   523 appears 880 times and is \" so\"\n",
      "Token  1169 appears 844 times and is \"the\"\n",
      "Token   530 appears 843 times and is \" one\"\n",
      "Token 22206 appears 843 times and is \" whale\"\n",
      "Token   345 appears 837 times and is \" you\"\n",
      "Token   220 appears 784 times and is \" \"\n",
      "Token   393 appears 737 times and is \" or\"\n",
      "Token   423 appears 725 times and is \" have\"\n",
      "Token   550 appears 719 times and is \" had\"\n",
      "Token   564 appears 700 times and is \" �\"\n",
      "Token   547 appears 641 times and is \" were\"\n",
      "Token   612 appears 637 times and is \" there\"\n",
      "Token   317 appears 614 times and is \" A\"\n",
      "Token   502 appears 610 times and is \" me\"\n",
      "Token   783 appears 598 times and is \" now\"\n",
      "Token   281 appears 588 times and is \" an\"\n",
      "Token   543 appears 578 times and is \" which\"\n",
      "Token   511 appears 570 times and is \" their\"\n",
      "Token   306 appears 567 times and is \"ly\"\n",
      "Token   389 appears 565 times and is \" are\"\n",
      "Token   617 appears 544 times and is \" some\"\n",
      "Token   484 appears 542 times and is \" they\"\n",
      "Token   616 appears 539 times and is \" my\"\n",
      "Token   788 appears 531 times and is \" then\"\n",
      "Token  5976 appears 521 times and is \"hab\"\n",
      "Token   276 appears 517 times and is \"ed\"\n",
      "Token   278 appears 515 times and is \"ing\"\n",
      "Token   503 appears 509 times and is \" out\"\n",
      "Token   383 appears 507 times and is \" The\"\n",
      "Token  2402 appears 505 times and is \" upon\"\n",
      "Token   588 appears 502 times and is \" like\"\n",
      "Token   618 appears 499 times and is \" when\"\n",
      "Token   510 appears 494 times and is \" up\"\n",
      "Token   887 appears 491 times and is \" But\"\n",
      "Token   656 appears 484 times and is \" into\"\n",
      "Token   582 appears 477 times and is \" man\"\n",
      "Token   645 appears 473 times and is \" no\"\n",
      "Token    83 appears 469 times and is \"t\"\n",
      "Token  4074 appears 466 times and is \" ship\"\n",
      "Token   517 appears 461 times and is \" more\"\n",
      "Token   392 appears 456 times and is \"and\"\n",
      "Token   606 appears 438 times and is \" them\"\n",
      "Token  1468 appears 419 times and is \" old\"\n",
      "Token   356 appears 419 times and is \" we\"\n",
      "Token  9838 appears 404 times and is \" ye\"\n",
      "Token  5417 appears 401 times and is \" sea\"\n",
      "Token   625 appears 399 times and is \" over\"\n",
      "Token    62 appears 397 times and is \"_\"\n",
      "Token   611 appears 395 times and is \" if\"\n",
      "Token   587 appears 389 times and is \" been\"\n",
      "Token   584 appears 386 times and is \" other\"\n",
      "Token   644 appears 385 times and is \" what\"\n",
      "Token   561 appears 381 times and is \" would\"\n",
      "Token    88 appears 372 times and is \"y\"\n",
      "Token   777 appears 356 times and is \" these\"\n",
      "Token   481 appears 353 times and is \" will\"\n",
      "Token   663 appears 352 times and is \" its\"\n",
      "Token   259 appears 346 times and is \"in\"\n",
      "Token   691 appears 341 times and is \" only\"\n",
      "Token   597 appears 339 times and is \" any\"\n"
     ]
    }
   ],
   "source": [
    "# most freq 100 tokens\n",
    "uniq, counts = np.unique(tokens, return_counts=True)\n",
    "freqidx = np.argsort(counts)[::-1]\n",
    "top100 = uniq[freqidx[:100]]\n",
    "\n",
    "for t in top100:\n",
    "    print(f'Token {t:5} appears {torch.sum(tokens==t)} times and is \"{tokenizer.decode(t)}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e3135bb-34a5-4e9a-bd97-9dd303da9a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numreps = 10 # num of random repetitions\n",
    "numtoks = 100 # oputput length\n",
    "\n",
    "tokenUsage = np.zeros((2,2)) # [pre/post, freeze/train]\n",
    "# random starting tokens\n",
    "randstarts = torch.randint(tokenizer.vocab_size, (numreps,1)).to(device) # this creates a 10x1 matrix [10 btaches of one single starting token]\n",
    "\n",
    "# FREEZE: generate and store tokens\n",
    "outFreeze = modelFreeze.generate(\n",
    "    randstarts,\n",
    "    max_length  = numtoks+1, #the first token is the row start in randstarts, so you need 100+1 total toks in output of generate()\n",
    "    min_length = numtoks+1, # guarantee that model should generarte exact;y 100 toks\n",
    "    do_sample = True,\n",
    "    pad_token_id = tokenizer.encode(tokenizer.eos_token)[0]).cpu()\n",
    "genTokensFreeze = outFreeze[:,1:].reshape(-1)\n",
    "\n",
    "\n",
    "# TRAIN: same as above\n",
    "outTrain = modelTrain.generate(\n",
    "    randstarts,\n",
    "    max_length  = numtoks+1, #the first token is the row start in randstarts, so you need 100+1 total toks in output of generate()\n",
    "    min_length = numtoks+1, # guarantee that model should generarte exact;y 100 toks\n",
    "    do_sample = True,\n",
    "    pad_token_id = tokenizer.encode(tokenizer.eos_token)[0]).cpu()\n",
    "genTokensTrain = outTrain[:,1:].reshape(-1)\n",
    "\n",
    "\n",
    "tokenUsage[0,0] = np.mean(100*np.isin(genTokensFreeze,top100))\n",
    "tokenUsage[0,1] = np.mean(100*np.isin(genTokensTrain,top100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e9cda33-e639-4793-9354-4479e69d02ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45. , 44.8],\n",
       "       [ 0. ,  0. ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenUsage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13865a15-9495-4909-a6ec-c272705a5c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b91be6ca-2641-43f0-8836-bb0dc66af6de",
   "metadata": {},
   "source": [
    "Now do targeted precision freezing\n",
    "\n",
    "For eg: we do freezing for attention weights(QKV) in layers upto 6 and from 6+ train them\n",
    "\n",
    "This means we train on only the later layers\n",
    "|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a95529b2-a929-4fc6-95d0-530ae7bf91b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transformer', 'wte', 'weight']\n",
      "['transformer', 'wpe', 'weight']\n",
      "['transformer', 'h', '0', 'ln_1', 'weight']\n",
      "['transformer', 'h', '0', 'ln_1', 'bias']\n",
      "['transformer', 'h', '0', 'attn', 'attention', 'k_proj', 'weight']\n",
      "['transformer', 'h', '0', 'attn', 'attention', 'v_proj', 'weight']\n",
      "['transformer', 'h', '0', 'attn', 'attention', 'q_proj', 'weight']\n",
      "['transformer', 'h', '0', 'attn', 'attention', 'out_proj', 'weight']\n",
      "['transformer', 'h', '0', 'attn', 'attention', 'out_proj', 'bias']\n",
      "['transformer', 'h', '0', 'ln_2', 'weight']\n",
      "['transformer', 'h', '0', 'ln_2', 'bias']\n",
      "['transformer', 'h', '0', 'mlp', 'c_fc', 'weight']\n",
      "['transformer', 'h', '0', 'mlp', 'c_fc', 'bias']\n",
      "['transformer', 'h', '0', 'mlp', 'c_proj', 'weight']\n",
      "['transformer', 'h', '0', 'mlp', 'c_proj', 'bias']\n",
      "['transformer', 'h', '1', 'ln_1', 'weight']\n",
      "['transformer', 'h', '1', 'ln_1', 'bias']\n",
      "['transformer', 'h', '1', 'attn', 'attention', 'k_proj', 'weight']\n",
      "['transformer', 'h', '1', 'attn', 'attention', 'v_proj', 'weight']\n",
      "['transformer', 'h', '1', 'attn', 'attention', 'q_proj', 'weight']\n",
      "['transformer', 'h', '1', 'attn', 'attention', 'out_proj', 'weight']\n",
      "['transformer', 'h', '1', 'attn', 'attention', 'out_proj', 'bias']\n",
      "['transformer', 'h', '1', 'ln_2', 'weight']\n",
      "['transformer', 'h', '1', 'ln_2', 'bias']\n",
      "['transformer', 'h', '1', 'mlp', 'c_fc', 'weight']\n",
      "['transformer', 'h', '1', 'mlp', 'c_fc', 'bias']\n",
      "['transformer', 'h', '1', 'mlp', 'c_proj', 'weight']\n",
      "['transformer', 'h', '1', 'mlp', 'c_proj', 'bias']\n",
      "['transformer', 'h', '2', 'ln_1', 'weight']\n",
      "['transformer', 'h', '2', 'ln_1', 'bias']\n",
      "['transformer', 'h', '2', 'attn', 'attention', 'k_proj', 'weight']\n",
      "['transformer', 'h', '2', 'attn', 'attention', 'v_proj', 'weight']\n",
      "['transformer', 'h', '2', 'attn', 'attention', 'q_proj', 'weight']\n",
      "['transformer', 'h', '2', 'attn', 'attention', 'out_proj', 'weight']\n",
      "['transformer', 'h', '2', 'attn', 'attention', 'out_proj', 'bias']\n",
      "['transformer', 'h', '2', 'ln_2', 'weight']\n",
      "['transformer', 'h', '2', 'ln_2', 'bias']\n",
      "['transformer', 'h', '2', 'mlp', 'c_fc', 'weight']\n",
      "['transformer', 'h', '2', 'mlp', 'c_fc', 'bias']\n",
      "['transformer', 'h', '2', 'mlp', 'c_proj', 'weight']\n",
      "['transformer', 'h', '2', 'mlp', 'c_proj', 'bias']\n",
      "['transformer', 'h', '3', 'ln_1', 'weight']\n",
      "['transformer', 'h', '3', 'ln_1', 'bias']\n",
      "['transformer', 'h', '3', 'attn', 'attention', 'k_proj', 'weight']\n",
      "['transformer', 'h', '3', 'attn', 'attention', 'v_proj', 'weight']\n",
      "['transformer', 'h', '3', 'attn', 'attention', 'q_proj', 'weight']\n",
      "['transformer', 'h', '3', 'attn', 'attention', 'out_proj', 'weight']\n",
      "['transformer', 'h', '3', 'attn', 'attention', 'out_proj', 'bias']\n",
      "['transformer', 'h', '3', 'ln_2', 'weight']\n",
      "['transformer', 'h', '3', 'ln_2', 'bias']\n",
      "['transformer', 'h', '3', 'mlp', 'c_fc', 'weight']\n",
      "['transformer', 'h', '3', 'mlp', 'c_fc', 'bias']\n",
      "['transformer', 'h', '3', 'mlp', 'c_proj', 'weight']\n",
      "['transformer', 'h', '3', 'mlp', 'c_proj', 'bias']\n",
      "['transformer', 'h', '4', 'ln_1', 'weight']\n",
      "['transformer', 'h', '4', 'ln_1', 'bias']\n",
      "['transformer', 'h', '4', 'attn', 'attention', 'k_proj', 'weight']\n",
      "['transformer', 'h', '4', 'attn', 'attention', 'v_proj', 'weight']\n",
      "['transformer', 'h', '4', 'attn', 'attention', 'q_proj', 'weight']\n",
      "['transformer', 'h', '4', 'attn', 'attention', 'out_proj', 'weight']\n",
      "['transformer', 'h', '4', 'attn', 'attention', 'out_proj', 'bias']\n",
      "['transformer', 'h', '4', 'ln_2', 'weight']\n",
      "['transformer', 'h', '4', 'ln_2', 'bias']\n",
      "['transformer', 'h', '4', 'mlp', 'c_fc', 'weight']\n",
      "['transformer', 'h', '4', 'mlp', 'c_fc', 'bias']\n",
      "['transformer', 'h', '4', 'mlp', 'c_proj', 'weight']\n",
      "['transformer', 'h', '4', 'mlp', 'c_proj', 'bias']\n",
      "['transformer', 'h', '5', 'ln_1', 'weight']\n",
      "['transformer', 'h', '5', 'ln_1', 'bias']\n",
      "['transformer', 'h', '5', 'attn', 'attention', 'k_proj', 'weight']\n",
      "['transformer', 'h', '5', 'attn', 'attention', 'v_proj', 'weight']\n",
      "['transformer', 'h', '5', 'attn', 'attention', 'q_proj', 'weight']\n",
      "['transformer', 'h', '5', 'attn', 'attention', 'out_proj', 'weight']\n",
      "['transformer', 'h', '5', 'attn', 'attention', 'out_proj', 'bias']\n",
      "['transformer', 'h', '5', 'ln_2', 'weight']\n",
      "['transformer', 'h', '5', 'ln_2', 'bias']\n",
      "['transformer', 'h', '5', 'mlp', 'c_fc', 'weight']\n",
      "['transformer', 'h', '5', 'mlp', 'c_fc', 'bias']\n",
      "['transformer', 'h', '5', 'mlp', 'c_proj', 'weight']\n",
      "['transformer', 'h', '5', 'mlp', 'c_proj', 'bias']\n",
      "['transformer', 'h', '6', 'ln_1', 'weight']\n",
      "['transformer', 'h', '6', 'ln_1', 'bias']\n",
      "['transformer', 'h', '6', 'attn', 'attention', 'k_proj', 'weight']\n",
      "['transformer', 'h', '6', 'attn', 'attention', 'v_proj', 'weight']\n",
      "['transformer', 'h', '6', 'attn', 'attention', 'q_proj', 'weight']\n",
      "['transformer', 'h', '6', 'attn', 'attention', 'out_proj', 'weight']\n",
      "['transformer', 'h', '6', 'attn', 'attention', 'out_proj', 'bias']\n",
      "['transformer', 'h', '6', 'ln_2', 'weight']\n",
      "['transformer', 'h', '6', 'ln_2', 'bias']\n",
      "['transformer', 'h', '6', 'mlp', 'c_fc', 'weight']\n",
      "['transformer', 'h', '6', 'mlp', 'c_fc', 'bias']\n",
      "['transformer', 'h', '6', 'mlp', 'c_proj', 'weight']\n",
      "['transformer', 'h', '6', 'mlp', 'c_proj', 'bias']\n",
      "['transformer', 'h', '7', 'ln_1', 'weight']\n",
      "['transformer', 'h', '7', 'ln_1', 'bias']\n",
      "['transformer', 'h', '7', 'attn', 'attention', 'k_proj', 'weight']\n",
      "['transformer', 'h', '7', 'attn', 'attention', 'v_proj', 'weight']\n",
      "['transformer', 'h', '7', 'attn', 'attention', 'q_proj', 'weight']\n",
      "['transformer', 'h', '7', 'attn', 'attention', 'out_proj', 'weight']\n",
      "['transformer', 'h', '7', 'attn', 'attention', 'out_proj', 'bias']\n",
      "['transformer', 'h', '7', 'ln_2', 'weight']\n",
      "['transformer', 'h', '7', 'ln_2', 'bias']\n",
      "['transformer', 'h', '7', 'mlp', 'c_fc', 'weight']\n",
      "['transformer', 'h', '7', 'mlp', 'c_fc', 'bias']\n",
      "['transformer', 'h', '7', 'mlp', 'c_proj', 'weight']\n",
      "['transformer', 'h', '7', 'mlp', 'c_proj', 'bias']\n",
      "['transformer', 'h', '8', 'ln_1', 'weight']\n",
      "['transformer', 'h', '8', 'ln_1', 'bias']\n",
      "['transformer', 'h', '8', 'attn', 'attention', 'k_proj', 'weight']\n",
      "['transformer', 'h', '8', 'attn', 'attention', 'v_proj', 'weight']\n",
      "['transformer', 'h', '8', 'attn', 'attention', 'q_proj', 'weight']\n",
      "['transformer', 'h', '8', 'attn', 'attention', 'out_proj', 'weight']\n",
      "['transformer', 'h', '8', 'attn', 'attention', 'out_proj', 'bias']\n",
      "['transformer', 'h', '8', 'ln_2', 'weight']\n",
      "['transformer', 'h', '8', 'ln_2', 'bias']\n",
      "['transformer', 'h', '8', 'mlp', 'c_fc', 'weight']\n",
      "['transformer', 'h', '8', 'mlp', 'c_fc', 'bias']\n",
      "['transformer', 'h', '8', 'mlp', 'c_proj', 'weight']\n",
      "['transformer', 'h', '8', 'mlp', 'c_proj', 'bias']\n",
      "['transformer', 'h', '9', 'ln_1', 'weight']\n",
      "['transformer', 'h', '9', 'ln_1', 'bias']\n",
      "['transformer', 'h', '9', 'attn', 'attention', 'k_proj', 'weight']\n",
      "['transformer', 'h', '9', 'attn', 'attention', 'v_proj', 'weight']\n",
      "['transformer', 'h', '9', 'attn', 'attention', 'q_proj', 'weight']\n",
      "['transformer', 'h', '9', 'attn', 'attention', 'out_proj', 'weight']\n",
      "['transformer', 'h', '9', 'attn', 'attention', 'out_proj', 'bias']\n",
      "['transformer', 'h', '9', 'ln_2', 'weight']\n",
      "['transformer', 'h', '9', 'ln_2', 'bias']\n",
      "['transformer', 'h', '9', 'mlp', 'c_fc', 'weight']\n",
      "['transformer', 'h', '9', 'mlp', 'c_fc', 'bias']\n",
      "['transformer', 'h', '9', 'mlp', 'c_proj', 'weight']\n",
      "['transformer', 'h', '9', 'mlp', 'c_proj', 'bias']\n",
      "['transformer', 'h', '10', 'ln_1', 'weight']\n",
      "['transformer', 'h', '10', 'ln_1', 'bias']\n",
      "['transformer', 'h', '10', 'attn', 'attention', 'k_proj', 'weight']\n",
      "['transformer', 'h', '10', 'attn', 'attention', 'v_proj', 'weight']\n",
      "['transformer', 'h', '10', 'attn', 'attention', 'q_proj', 'weight']\n",
      "['transformer', 'h', '10', 'attn', 'attention', 'out_proj', 'weight']\n",
      "['transformer', 'h', '10', 'attn', 'attention', 'out_proj', 'bias']\n",
      "['transformer', 'h', '10', 'ln_2', 'weight']\n",
      "['transformer', 'h', '10', 'ln_2', 'bias']\n",
      "['transformer', 'h', '10', 'mlp', 'c_fc', 'weight']\n",
      "['transformer', 'h', '10', 'mlp', 'c_fc', 'bias']\n",
      "['transformer', 'h', '10', 'mlp', 'c_proj', 'weight']\n",
      "['transformer', 'h', '10', 'mlp', 'c_proj', 'bias']\n",
      "['transformer', 'h', '11', 'ln_1', 'weight']\n",
      "['transformer', 'h', '11', 'ln_1', 'bias']\n",
      "['transformer', 'h', '11', 'attn', 'attention', 'k_proj', 'weight']\n",
      "['transformer', 'h', '11', 'attn', 'attention', 'v_proj', 'weight']\n",
      "['transformer', 'h', '11', 'attn', 'attention', 'q_proj', 'weight']\n",
      "['transformer', 'h', '11', 'attn', 'attention', 'out_proj', 'weight']\n",
      "['transformer', 'h', '11', 'attn', 'attention', 'out_proj', 'bias']\n",
      "['transformer', 'h', '11', 'ln_2', 'weight']\n",
      "['transformer', 'h', '11', 'ln_2', 'bias']\n",
      "['transformer', 'h', '11', 'mlp', 'c_fc', 'weight']\n",
      "['transformer', 'h', '11', 'mlp', 'c_fc', 'bias']\n",
      "['transformer', 'h', '11', 'mlp', 'c_proj', 'weight']\n",
      "['transformer', 'h', '11', 'mlp', 'c_proj', 'bias']\n",
      "['transformer', 'ln_f', 'weight']\n",
      "['transformer', 'ln_f', 'bias']\n"
     ]
    }
   ],
   "source": [
    "for name, param in modelFreeze.named_parameters():\n",
    "    splitstr = name.split('.')\n",
    "    print(splitstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8bd03ce-f92c-48d9-863c-12a548c6d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.h.6.attn.attention.k_proj.weight\n",
      "transformer.h.6.attn.attention.v_proj.weight\n",
      "transformer.h.6.attn.attention.q_proj.weight\n",
      "transformer.h.7.attn.attention.k_proj.weight\n",
      "transformer.h.7.attn.attention.v_proj.weight\n",
      "transformer.h.7.attn.attention.q_proj.weight\n",
      "transformer.h.8.attn.attention.k_proj.weight\n",
      "transformer.h.8.attn.attention.v_proj.weight\n",
      "transformer.h.8.attn.attention.q_proj.weight\n",
      "transformer.h.9.attn.attention.k_proj.weight\n",
      "transformer.h.9.attn.attention.v_proj.weight\n",
      "transformer.h.9.attn.attention.q_proj.weight\n",
      "transformer.h.10.attn.attention.k_proj.weight\n",
      "transformer.h.10.attn.attention.v_proj.weight\n",
      "transformer.h.10.attn.attention.q_proj.weight\n",
      "transformer.h.11.attn.attention.k_proj.weight\n",
      "transformer.h.11.attn.attention.v_proj.weight\n",
      "transformer.h.11.attn.attention.q_proj.weight\n"
     ]
    }
   ],
   "source": [
    "# test: idfy QKV weights of layer >5\n",
    "\n",
    "for name, param in modelFreeze.named_parameters():\n",
    "    splitstr = name.split('.')\n",
    "    if (len(splitstr)>5) and (splitstr[3]=='attn'):\n",
    "        if(int(splitstr[2])>5) and (splitstr[5][0] in 'qvk'):\n",
    "            print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02d78f3b-6ad7-4f2a-9652-9f8bb18d033c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('s' in 'qvk')\n",
    "print('q' in 'qvk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f9ef7f7-e9ed-44b0-9de6-ddd57ed5c284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Layer transformer.wte.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.wpe.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.0.ln_1.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.0.ln_1.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.0.ln_2.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.0.ln_2.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.0.mlp.c_fc.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.0.mlp.c_fc.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.0.mlp.c_proj.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.0.mlp.c_proj.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.1.ln_1.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.1.ln_1.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.1.ln_2.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.1.ln_2.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.1.mlp.c_fc.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.1.mlp.c_fc.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.1.mlp.c_proj.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.1.mlp.c_proj.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.2.ln_1.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.2.ln_1.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.2.ln_2.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.2.ln_2.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.2.mlp.c_fc.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.2.mlp.c_fc.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.2.mlp.c_proj.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.2.mlp.c_proj.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.3.ln_1.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.3.ln_1.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.3.ln_2.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.3.ln_2.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.3.mlp.c_fc.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.3.mlp.c_fc.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.3.mlp.c_proj.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.3.mlp.c_proj.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.4.ln_1.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.4.ln_1.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.4.ln_2.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.4.ln_2.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.4.mlp.c_fc.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.4.mlp.c_fc.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.4.mlp.c_proj.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.4.mlp.c_proj.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.5.ln_1.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.5.ln_1.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.5.ln_2.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.5.ln_2.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.5.mlp.c_fc.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.5.mlp.c_fc.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.5.mlp.c_proj.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.5.mlp.c_proj.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.6.ln_1.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.6.ln_1.bias is frozen (.requires_grad = False\n",
      "+++ Layer transformer.h.6.attn.attention.k_proj.weight is trainable (.requires_grad = True\n",
      "+++ Layer transformer.h.6.attn.attention.v_proj.weight is trainable (.requires_grad = True\n",
      "+++ Layer transformer.h.6.attn.attention.q_proj.weight is trainable (.requires_grad = True\n",
      "--- Layer transformer.h.6.ln_2.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.6.ln_2.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.6.mlp.c_fc.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.6.mlp.c_fc.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.6.mlp.c_proj.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.6.mlp.c_proj.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.7.ln_1.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.7.ln_1.bias is frozen (.requires_grad = False\n",
      "+++ Layer transformer.h.7.attn.attention.k_proj.weight is trainable (.requires_grad = True\n",
      "+++ Layer transformer.h.7.attn.attention.v_proj.weight is trainable (.requires_grad = True\n",
      "+++ Layer transformer.h.7.attn.attention.q_proj.weight is trainable (.requires_grad = True\n",
      "--- Layer transformer.h.7.ln_2.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.7.ln_2.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.7.mlp.c_fc.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.7.mlp.c_fc.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.7.mlp.c_proj.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.7.mlp.c_proj.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.8.ln_1.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.8.ln_1.bias is frozen (.requires_grad = False\n",
      "+++ Layer transformer.h.8.attn.attention.k_proj.weight is trainable (.requires_grad = True\n",
      "+++ Layer transformer.h.8.attn.attention.v_proj.weight is trainable (.requires_grad = True\n",
      "+++ Layer transformer.h.8.attn.attention.q_proj.weight is trainable (.requires_grad = True\n",
      "--- Layer transformer.h.8.ln_2.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.8.ln_2.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.8.mlp.c_fc.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.8.mlp.c_fc.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.8.mlp.c_proj.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.8.mlp.c_proj.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.9.ln_1.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.9.ln_1.bias is frozen (.requires_grad = False\n",
      "+++ Layer transformer.h.9.attn.attention.k_proj.weight is trainable (.requires_grad = True\n",
      "+++ Layer transformer.h.9.attn.attention.v_proj.weight is trainable (.requires_grad = True\n",
      "+++ Layer transformer.h.9.attn.attention.q_proj.weight is trainable (.requires_grad = True\n",
      "--- Layer transformer.h.9.ln_2.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.9.ln_2.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.9.mlp.c_fc.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.9.mlp.c_fc.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.9.mlp.c_proj.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.9.mlp.c_proj.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.10.ln_1.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.10.ln_1.bias is frozen (.requires_grad = False\n",
      "+++ Layer transformer.h.10.attn.attention.k_proj.weight is trainable (.requires_grad = True\n",
      "+++ Layer transformer.h.10.attn.attention.v_proj.weight is trainable (.requires_grad = True\n",
      "+++ Layer transformer.h.10.attn.attention.q_proj.weight is trainable (.requires_grad = True\n",
      "--- Layer transformer.h.10.ln_2.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.10.ln_2.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.10.mlp.c_fc.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.10.mlp.c_fc.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.10.mlp.c_proj.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.10.mlp.c_proj.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.11.ln_1.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.11.ln_1.bias is frozen (.requires_grad = False\n",
      "+++ Layer transformer.h.11.attn.attention.k_proj.weight is trainable (.requires_grad = True\n",
      "+++ Layer transformer.h.11.attn.attention.v_proj.weight is trainable (.requires_grad = True\n",
      "+++ Layer transformer.h.11.attn.attention.q_proj.weight is trainable (.requires_grad = True\n",
      "--- Layer transformer.h.11.ln_2.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.11.ln_2.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.11.mlp.c_fc.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.11.mlp.c_fc.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.11.mlp.c_proj.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.h.11.mlp.c_proj.bias is frozen (.requires_grad = False\n",
      "--- Layer transformer.ln_f.weight is frozen (.requires_grad = False\n",
      "--- Layer transformer.ln_f.bias is frozen (.requires_grad = False\n"
     ]
    }
   ],
   "source": [
    "for name,param in modelFreeze.named_parameters():\n",
    "    splitstr = name.split('.')\n",
    "    if (len(splitstr)>5) and (splitstr[3]=='attn'):\n",
    "        if(int(splitstr[2])>5) and (splitstr[5][0] in 'qvk'):\n",
    "            param.requires_grad = True\n",
    "            print(f'+++ Layer {name} is trainable (.requires_grad = {param.requires_grad}')\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "        print(f'--- Layer {name} is frozen (.requires_grad = {param.requires_grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d4ea00-3eba-4152-b9b2-bdb3cc1759cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42820d7e-c4fe-48dc-8e91-09abfc36af99",
   "metadata": {},
   "source": [
    "Now train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61753fd1-060e-417c-8f0b-e77c7ed8ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we also track learning related changes in a random weight (h[6].attn.k) and also time the training [using delta norm]\n",
    "# for both frozen and non frozen models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87511da1-31ad-48fd-bfb3-e8ae3890f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizerFreeze = torch.optim.AdamW(modelFreeze.parameters(), lr=.0005)\n",
    "optimizerTrain = torch.optim.AdamW(modelTrain.parameters(), lr=.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "769b8a43-86c9-4340-a3c3-a44a31402020",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 256\n",
    "batch_size = 16\n",
    "num_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bcd0297-edcf-46b4-a800-286713c42a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0/100, losses (Freeze/Train):: 3.77 / 3.77\n",
      "Sample 25/100, losses (Freeze/Train):: 3.30 / 3.37\n",
      "Sample 50/100, losses (Freeze/Train):: 3.42 / 3.46\n",
      "Sample 75/100, losses (Freeze/Train):: 3.27 / 3.00\n"
     ]
    }
   ],
   "source": [
    "losses = np.zeros((num_samples,2))\n",
    "delta_norm_em = np.zeros((num_samples,2))\n",
    "\n",
    "timeTrain = 0\n",
    "timeFreeze = 0\n",
    "\n",
    "# grab the initial MLP weights for comparison\n",
    "prev_emFreeze = modelFreeze.transformer.h[6].attn.attention.k_proj.weight.detach() + 0\n",
    "prev_emTrain = modelTrain.transformer.h[6].attn.attention.k_proj.weight.detach() + 0\n",
    "\n",
    "\n",
    "for sampli in range(num_samples):\n",
    "    ix = torch.randint(len(tokens)-seq_len,size=(batch_size,))\n",
    "    X = tokens[ix[:,None]+ torch.arange(seq_len)].to(device)\n",
    "\n",
    "    # FREEZE fine tuining \n",
    "    # fwd pass and get loss\n",
    "    start_time = time.time()\n",
    "    modelFreeze.zero_grad()\n",
    "    outputs= modelFreeze(X,labels=X)\n",
    "\n",
    "    #backrpop and store loss\n",
    "    outputs.loss.backward()\n",
    "    optimizerFreeze.step()\n",
    "    losses[sampli, 0] = outputs.loss.item()\n",
    "    timeFreeze += time.time() - start_time\n",
    "    ###c------------\n",
    "\n",
    "\n",
    "    # TRAIN fine tuining \n",
    "    # fwd pass and get loss\n",
    "    start_time = time.time()\n",
    "    modelTrain.zero_grad()\n",
    "    outputs= modelTrain(X,labels=X)\n",
    "\n",
    "    #backrpop and store loss\n",
    "    outputs.loss.backward()\n",
    "    optimizerTrain.step()\n",
    "    losses[sampli, 1] = outputs.loss.item()\n",
    "    timeTrain += time.time() - start_time\n",
    "    ###c------------\n",
    "\n",
    "    #matrix norm to asses change in MLP layer\n",
    "    delta_norm_em[sampli,0] = torch.norm(modelFreeze.transformer.h[6].attn.attention.k_proj.weight.detach() - prev_emFreeze)\n",
    "    prev_emFreeze = modelFreeze.transformer.h[6].attn.attention.k_proj.weight.detach()\n",
    "\n",
    "    delta_norm_em[sampli,1] = torch.norm(modelTrain.transformer.h[6].attn.attention.k_proj.weight.detach() - prev_emTrain)\n",
    "    prev_emTrain = modelTrain.transformer.h[6].attn.attention.k_proj.weight.detach() + 0\n",
    "    \n",
    "    # sum the batch loss\n",
    "\n",
    "    if sampli%25==0:\n",
    "        print(f'Sample {sampli}/{num_samples}, losses (Freeze/Train):: {losses[sampli,0]:.2f} / {losses[sampli,1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "881e733c-cc59-4e90-a20c-9752fd0c0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "#plot of losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994dfd26-7142-472c-a05f-e63a3cd71bbd",
   "metadata": {},
   "source": [
    "![title](../images/losses_freeze_train.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "714cd415-240b-4790-b701-a94d0fc7f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the percent of common100 tokens of moby dick\n",
    "\n",
    "# this is not expected ---ideally fully trained model would be picking most100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839b92f0-c151-477f-8cd8-99708d2c6c20",
   "metadata": {},
   "source": [
    "![title](../images/common100Mobydick.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4dec93a-8b19-43cd-9b0f-c9d9ba7076f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hwo the attention weights changed over training (norm thing)\n",
    "\n",
    "# plot shows the weights change a lot initially in the training and becomes stable iduringg later parts of training\n",
    "# graph also shows most of chnages happen in the layers trainnabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa035092-1e7d-4d12-97b1-b6bee14ff138",
   "metadata": {},
   "source": [
    "![title](../images/normChange.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfd861f8-8246-4600-95d8-e13c084d34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to show the trainnig times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1d58da-9b9d-41c5-901c-5314fed1f7c0",
   "metadata": {},
   "source": [
    "![title](../images/trainTimes.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761de1b-b84c-41f0-886a-3fad62abce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter-env)",
   "language": "python",
   "name": "jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
